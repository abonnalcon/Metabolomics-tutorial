{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; padding:5px; background-color:rgb(252, 253, 255); border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "    <font color='red'>To begin: Click anywhere in this cell and press <kbd>Run</kbd> on the menu bar. This executes the current cell and then highlights the next cell. There are two types of cell. A <i>text cell</i> and a <i>code cell</i>. When you <kbd>Run</kbd> a text cell (<i>we are in a text cell now</i>), you advance to the next cell without executing any code. When you <kbd>Run</kbd> a code cell (<i>identified by <span style=\"font-family: courier; color:black; background-color:white;\">In[ ]:</span> to the left of the cell</i>) you advance to the next cell after executing all the Python code within that cell. Any visual results produced by the code (text/figures) are reported directly below that cell. Press <kbd>Run</kbd> again. Repeat this process until the end of the notebook. <b>NOTE:</b> All the cells in this notebook can be automatically executed sequentially by clicking <kbd>Kernel</kbd><font color='black'>→</font><kbd>Restart and Run All</kbd>. Should anything crash then restart the Jupyter Kernel by clicking <kbd>Kernel</kbd><font color='black'>→</font><kbd>Restart</kbd>, and start again from the top.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<h1 id=\"tutorial1\" style=\"text-align: justify\">Tutorial: NMR and LC-MS Metabolomics Data Analysis Workflow</h1>\n",
    "\n",
    "<p style=\"text-align: justify\"><br>  \n",
    "</div>\n",
    "\n",
    "<p  style=\"text-align: justify\">\n",
    "This Jupyter notebook uses Python and R language and describes a typical metabolomics data analysis workflow for a study with a binary classification outcome. The main steps included are: </p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Import metabolite &amp; experimental data from an Excel sheet. </li>\n",
    "\n",
    "<li style=\"text-align: justify\">Pooled QC-based data cleaning.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Principal Component Analysis visualisation to check data quality.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Two-class univariate statistics.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Multivariate analysis using Partial Least Squares Discriminant Analysis (PLS-DA) including:\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">model optimisation (R<sup>2</sup> vs Q<sup>2</sup>).</li>\n",
    "\n",
    "<li style=\"text-align: justify\">permutation testing, model prediction metrics.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">feature importance.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">model prediction data visualisations.</li></ul>\n",
    "</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Export statistical tables to Excel sheets.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">The study used in this tutorial has been previously published as an open access article <a href=\"https://www.nature.com/articles/bjc2015414\">Chan et al. (2016)</a>, in the British Journal of Cancer, and the deconvolved and annotated data file deposited at the <a href=\"http://www.metabolomicsworkbench.org\">Metabolomics Workbench data repository</a> (Project ID PR000699). The data can be accessed directly via its project <a href=\"http://dx.doi.org/DOI:10.21228/M8B10B\">DOI:10.21228/M8B10B</a> <sup>1</sup>H-NMR spectra were acquired at Canada’s National High Field Nuclear Magnetic Resonance Centre (NANUC) using a 600 MHz Varian Inova spectrometer. Spectral deconvolution and metabolite annotation was performed using the <a href=\"https://www.chenomx.com/software/\">Chenomx NMR Suite v7.6</a>. Unfortunately, the Raw NMR data is unavailable.</p>\n",
    "\n",
    "<p  style=\"text-align: justify\"> This notebook is based on the Metabolomics workflow tutorial part of the following review: <br>\n",
    "     <a href=\"https://doi.org/10.1007/s11306-019-1588-0\"> \"Toward collaborative open data science in metabolomics using Jupyter Notebooks and cloud computing\"<br>\n",
    "    <a href=\"https://github.com/CIMCB/MetabWorkflowTutorial\"> All the original notebooks are available here \n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:5px;  border: 10px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"40\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "<b style=\"text-align: justify\">Red boxes (cog icon) provide suggestions for changing the functionality of the subsequent code cell by editing (or substituting) one or more lines of code.</b><br><br>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,210); padding:5px;  border: 10px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"40\" src=\"images/mouse.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "<b style=\"text-align: justify\"> Green boxes (mouse icon) provide suggestions for interacting with the visual results generated by a code cell. For example, the first green box in the notebook describes how to sort and colour data in the embedded data tables.</b><br>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,255); padding:5px;  border: 10px solid rgb(255, 250, 250); border-bottom: 10px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"40\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "<b style=\"text-align: justify\">Blue boxes (lightbulb icon) provide further information about the theoretical reasoning behind a block of code or visualisation. This information is not essential to understand Jupyter notebooks but may be of general educational utility and interest to new metabolomics data scientists.</b><br>\n",
    "</div></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:2px; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "<h2 id=\"1importpackagesmodules\" style=\"text-align: justify\">1. Import Packages/Modules</h2>\n",
    "\n",
    "<p style=\"text-align: justify\">The first code cell of this tutorial (below this text box) imports <a href=\"https://docs.python.org/3/tutorial/modules.html\"><em>packages</em> and <em>modules</em></a> into the Jupyter environment. <em>Packages</em> and <em>modules</em> provide additional functions and tools that extend the basic functionality of the Python language.\n",
    "<br></p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,255); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">All the code embedded in this example notebook is written using the Python programming language (<a href=\"http://www.python.org\">python.org</a>) and is based upon extensions of popular open source packages with high levels of support. \n",
    "    \n",
    "<em>Note:</em> a tutorial on the python programming language in itself is beyond the scope of this notebook. For more information on using Python and Jupyter Notebooks please refer to the excellent: \n",
    "<a href=\"https://mybinder.org/v2/gh/jakevdp/PythonDataScienceHandbook/master?filepath=notebooks%2FIndex.ipynb\">Python Data Science Handbook (Jake VanderPlas, 2016)</a>, which is in itself a Jupyter Notebook deployed via <a href=\"https://mybinder.org\">Binder</a>.</li>\n",
    "</ul>\n",
    "</div> </div>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "<p style=\"text-align: justify\">The first code cell of this tutorial (below this text box) imports <a href=\"https://docs.python.org/3/tutorial/modules.html\"><em>packages</em> and <em>modules</em></a> into the Jupyter environment. <em>Packages</em> and <em>modules</em> provide additional functions and tools that extend the basic functionality of the Python language. We will need the following tools  to analyse the data in this tutorial:<br></p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\"><a href=\"http://www.numpy.org/\"><code>numpy</code></a>: the fundamental package for scientific computing with Python, providing tools to work with arrays and linear algebra</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><a href=\"https://pandas.pydata.org/\"><code>pandas</code></a>: provides high-performance, easy-to-use data structures and data analysis tools</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><a href=\"http://beakerx.com/\"><code>beakerx</code></a>: provides interactive tools for the Jupyter notebook environment</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><a href=\"https://scikit-learn.org/stable/\"><code>sklearn</code></a>: tools for machine learning in Python\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\"><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\"><code>train_test_split</code></a>: a method to split arrays into random test/training subsets for cross-validation</li></ul>\n",
    "</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><a href=\"https://github.com/KevinMMendez/cimcb_lite\"><code>cimcb_lite</code></a>: a library of helpful functions provided by the authors</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\"><strong>Run the cell by clicking anywhere in the cell (the cell will be surrounded by a blue box) and then clicking <kbd>Run</kbd> in the Menu.</strong> <br>\n",
    "When successfully executed the cell will print <code>All packages successfully loaded</code> in the notebook below the cell.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cimcb_lite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a7433d21bc91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcimcb_lite\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbeakerx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_display_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# by default display pandas tables as BeakerX interactive tables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cimcb_lite'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from beakerx.object import beakerx\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cimcb_lite as cb\n",
    "\n",
    "beakerx.pandas_display_table()  # by default display pandas tables as BeakerX interactive tables\n",
    "\n",
    "print('All packages successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<h2 id=\"2loaddataandpeaksheet\" style=\"text-align: justify\">2. Load Data and Peak sheet</h2>\n",
    "\n",
    "<p style=\"text-align: justify\">The code cell below loads the <em>Data</em> and <em>Peak</em> sheets from an Excel file, using the CIMCB helper function <code>load_dataXL()</code>. When this is complete, you should see confirmation that Peak (stored in the <code>Peak</code> worksheet in the Excel file) and Data (stored in the <code>Data</code> worksheet in the Excel file) tables have been loaded.<br></p>\n",
    "\n",
    "<p style=\"text-align: justify\">This workflow requires data to be uploaded as a Microsoft Excel file, using the <a href=\"https://en.wikipedia.org/wiki/Tidy_data\">Tidy Data</a> framework (i.e. each column is a variable, and row is an observation). As such, the Excel file should contain a <em>Data Sheet</em> and <em>Peak Sheet</em>. The <em>Data Sheet</em> contains all the metabolite concentrations and metadata associated with each observation (requiring the inclusion of the columns: <em>Idx</em>, <em>SampleID</em>, and <em>Class</em>). The <em>Peak Sheet</em> contains all the metadata pertaining to each measured metabolite (requiring the inclusion of the columns: <em>Idx</em>, <em>Name</em>, and <em>Label</em>). Please inspect the <a href=\"GastricCancer_NMR.xlsx\">Excel file</a> used in this tutorial before proceeding. </p>\n",
    "\n",
    "<p style=\"text-align: justify\">The code cell below loads the <em>Data</em> and <em>Peak</em> sheets from an Excel file, using the CIMCB helper function <code>load_dataXL()</code>. When this is complete, you should see confirmation that Peak (stored in the <code>Peak</code> worksheet in the Excel file) and Data (stored in the <code>Data</code> worksheet in the Excel file) tables have been loaded:</p>\n",
    "\n",
    "<pre style=\"text-align: justify\"><code class=\"text language-text\">Loadings PeakFile: Peak\n",
    "Loadings DataFile: Data\n",
    "Data Table &amp; Peak Table is suitable.\n",
    "TOTAL SAMPLES: 140 TOTAL PEAKS: 149\n",
    "Done!\n",
    "</code></pre>\n",
    "\n",
    "<p style=\"text-align: justify\">Once loaded, the data is available for use in <a href=\"https://swcarpentry.github.io/python-novice-gapminder/02-variables/\"><em>variables</em></a> called <code>dataTable</code> and <code>peakTable</code>.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\"> \n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">There is a second datase included with this  tutorial which has been converted to standardised <a href=\"https://en.wikipedia.org/wiki/Tidy_data\">Tidy Data</a> format. This data has been previously published as an article <a href=\"https://link.springer.com/article/10.1007%2Fs11306-016-1059-9\">Gardlo et al. (2016)</a> in  <i>Metabolomics</i>. \n",
    "    \n",
    "Urine samples collected from newborns with perinatal asphyxia were analysed using a Dionex UltiMate 3000 RS system coupled to a triple quadrupole QTRAP 5500 tandem mass spectrometer. The deconvoluted and annotated file is deposited at the <a href=\"https://www.ebi.ac.uk/metabolights/\">Metabolights</a> data repository (Project ID <a href=\"https://www.ebi.ac.uk/metabolights/MTBLS290\">MTBLS290</a>). \n",
    "\n",
    "Please inspect the <a href=\"MTBLS290db.xlsx\">Excel file</a> before using it in this tutorial. To change the data set to be loaded into the notebook remove the <code>#</code> before <code>filename</code>,and press <mark><kbd>Run</kbd></mark> on the menu bar.\n",
    "\n",
    "<b>Note: if you change the name of the file in this code cell, you will also have to make changes to <a href=#5>Section 5</a> and <a href=#6>Section 6</a> (as indicated in the text cell above each) for the correct models to be built. It is probably best to come back to this excercise after finishing an initial walk-through of the complete tutorial using the default data set.</b></li>\n",
    "</ul>\n",
    "</div></div>\n",
    "\n",
    "<h3 id=\"run2NMR\" style=\"text-align: justify\">Important for the second analysis round when you will use NMR make sure to change the filename from the LC-MS</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The path to the input file (Excel spreadsheet)\n",
    "# Choose between NMR or LC-MS data - LC-MS is the default here\n",
    "\n",
    "filename = 'MTBLS290db.xlsx'\n",
    "# filename = 'GastricCancer_NMR.xlsx'# To use the NMR data instead of LC-MS remove the # before filename\n",
    "\n",
    "# Load Peak and Data tables into two variables\n",
    "dataTable, peakTable = cb.utils.load_dataXL(filename, DataSheet='Data', PeakSheet='Peak') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:2px; padding-left: 1em; padding-right: 1em;\">\n",
    "<h3 id=\"21displaythedatatable\" style=\"text-align: justify\">2.1 Display the <code>Data</code> table</h3>\n",
    "\n",
    "<p style=\"text-align: justify\">The <code>dataTable</code> table can be displayed interactively so we can inspect and check the imported values. To do this, we use the <code>display()</code> function.\n",
    "<br></p>\n",
    "<p style=\"text-align: justify\">Note that each row describes a single urine sample, where:</p>\n",
    "<ul>\n",
    "    <li style=\"text-align: justify\">Columns <b>M1</b> ... <b>M149</b> descibe metabolite concentrations.</li>\n",
    "    <li style=\"text-align: justify\">Column <b>SampleType</b> indicates whether the sample was a pooled QC or a study sample.</li>\n",
    "    <li style=\"text-align: justify\">Column <b>Class</b> indicates the clincal outcome observed for that individual: <i>GC</i> = Gastric Cancer , <i>BN</i> = Benign Tumor , <i>HE</i> = Healthy Control</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div style=\"background-color:rgb(210,250,210); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"60\" src=\"images/mouse.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Scroll up/down &amp; left/right using the scroll bars</li>\n",
    "<li style=\"text-align: justify\">Click on any column header to sort by that column (sort alternates between ascending and decending order)</li>\n",
    "<li style=\"text-align: justify\">Click on the left side of a header column for futher options \n",
    "<ul>\n",
    "<li style=\"text-align: justify\">for column <b>Class</b> click on <i>'color by unique'</i></li>\n",
    "<li style=\"text-align: justify\">for column <b>SampleType</b> click on <i>'sort ascending'</i> to group all the <em>QC</em> samples together.</li></ul>\n",
    "</li>\n",
    "<li style=\"text-align: justify\">Click on column header <b>index</b> to sort back into the orginal order.</li>\n",
    "</ul>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(dataTable) # View and check the dataTable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:5px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<h3 id=\"22displaythepeaksheet\" style=\"text-align: justify\">2.2. Display the <code>Peak</code> sheet</h3>\n",
    "\n",
    "<p style=\"text-align: justify\">The <code>peakTable</code> table can also be displayed interactively so we can inspect and check the imported values. To do this, we again use the <code>display()</code> function. For this example the imported data consists of 149 metabolites (the same as in the <code>dataTable</code> data)</p>\n",
    "\n",
    "<p style=\"text-align: justify\">Each row describes a single metabolite, where</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Column <strong>Idx</strong> is a unique metabolite index.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Column <strong>Name</strong> is the column header corresponding to this metabolite in the <code>dataTable</code> table.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Column <strong>Label</strong> provides a unique name for the metabolite (or a <code>uNNN</code> identifier)</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Column <strong>Perc_missing</strong> indicates what percentage of samples do not contain a measurement for this metabolite (missing data). </li>\n",
    "\n",
    "<li style=\"text-align: justify\">Column <strong>QC_RSD</strong> is a quality score representing the variation in measurements of this metabolite across all samples. </li>\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,210); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"60\" src=\"images/mouse.png\">\n",
    "<div style=\"padding-left:80px\"> \n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Click on the column header <strong>QC_RSD</strong> to sort the peaks by ascending value</li>\n",
    "<li style=\"text-align: justify\">Click on the left edge of the column header <strong>QC_RSD</strong> and select <em>'heatmap'</em></li>\n",
    "<li style=\"text-align: justify\">Scroll up/down to see how the \"quality\" of the peaks increase/decrease</li>\n",
    "</ul>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(peakTable) # View and check PeakTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<h2 id=\"3datacleaning\" style=\"text-align: justify\">3. Data Cleaning</h2>\n",
    "<p style=\"text-align: justify\">It is good practice to assess the quality of your data, and remove (clean out) any poorly measured metabolites, before performing any statistical or machine learning modelling <a href=\"https://link.springer.com/article/10.1007/s11306-018-1367-3\">Broadhurst <em>et al.</em> 2018</a>.</a> For the Gastric Cancer NMR data set used in this example we have already calculated some basic statistics for each metabolite and stored them in the Peak table. In this notebook we keep only metabolites that meet the following criteria:</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">a QC-RSD less than 20% </li>\n",
    "\n",
    "<li style=\"text-align: justify\">fewer than 10% of values are missing</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">When the data is cleaned, the number of remaining peaks will be reported.</p>\n",
    "</div>\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px; border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"60\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\"> \n",
    "    \n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Replace the code: <code>PeakTableClean = peakTable[(rsd &lt; 20) &amp; (percMiss &lt; 10]</code> with: <code>peakTableClean = peakTable[(rsd &lt; 10) &amp; (percMiss &lt; 5)]</code>. In doing this you will see the effect of making the data cleaning criteria more stringent. This will change the number of 'clean' metabolites.</li>\n",
    "</ul>\n",
    "</div></div>\n",
    "<div style=\"background-color:rgb(210,250,255); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"40\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">    \n",
    "<ul>\n",
    "<li style=\"text-align: justify\"><b>Note: Changing the number of clean metabolites will significantly change the outputs from all subsequent code cells.</b><br> So be sure to click on <mark><kbd>Cell</kbd></mark><font color='black'>→</font><mark><kbd>Run All Below</kbd></mark> then scroll down the notebook to see how changing this setting has changed all the cell outputs.</li>\n",
    "</ul>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean peak table \n",
    "\n",
    "rsd = peakTable['QC_RSD']  \n",
    "percMiss = peakTable['Perc_missing']  \n",
    "peakTableClean = peakTable[(rsd < 20) & (percMiss < 10)]   \n",
    "\n",
    "print(\"Number of peaks remaining: {}\".format(len(peakTableClean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<h2 id=\"4pcaqualityassesment\" style=\"text-align: justify\">4. PCA - Quality Assesment</h2>\n",
    "\n",
    "<p style=\"text-align: justify\">To provide a multivariate assesment of the quality of the cleaned data set it is good practice to perform a simple  <a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\">Principal Component Analysis</a> (PCA), after suitable <a href=\"https://doi.org/10.1186/1471-2164-7-142\">transforming &amp; scaling</a>. The PCA score plot is typically labelled by sample type (i.e. quality control (QC) or biological sample (Sample)). Data of high quality will have QCs that cluster tightly compared to the biological samples <a href=\"https://link.springer.com/article/10.1007/s11306-018-1367-3\">Broadhurst <em>et al.</em> 2018</a>. </p>\n",
    "\n",
    "<p style=\"text-align: justify\">First the metabolite data matrix is extracted from the <code>dataTable</code>, and transformed &amp; scaled:</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">A new variable <code>peaklist</code> is created, to hold the names (M1...Mn) of the metabolites to be used in subsequent statistical analysis</li>\n",
    "\n",
    "<li style=\"text-align: justify\">The peak data for all samples, corresponding to this list, is extracted from the <code>dataTable</code> table, and placed in a matrix <code>X</code></li>\n",
    "\n",
    "<li style=\"text-align: justify\">The values in <code>X</code> are log-transformed (<code>Xlog</code>)</li>\n",
    "\n",
    "<li style=\"text-align: justify\">The helper function <code>cb.utils.scale()</code> is used to scale the log-transformed data (<code>Xscale</code>)</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Missing values are imputed using a <em>k</em>-nearest neighbour approach (with three neighbours) to give the table <code>Xknn</code></li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">The transformed &amp; scaled dataset <code>Xknn</code> is used as input to PCA, using the helper function <code>cb.plot.pca()</code>. This returns plots of PCA scores and PCA loadings, for interpretation and quality assessment.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,210); padding:2px;border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/mouse.png\">\n",
    "<div style=\"padding-left:80px\"> \n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Hover over points in the PCA Score Plot to reveal corresponding sample information ('IDX' and 'SampleType'). </li>\n",
    "\n",
    "<li style=\"text-align: justify\">Hover over points in the PCA Loading Plot to reveal corresponding metabolite information ('Name','Label', and 'QC_RSD'). </li>\n",
    "\n",
    "<li style=\"text-align: justify\">In the menu at the top right corner of the figure click on the 'disk' icon to save the images.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">In the menu at the top right corner of the figure click on the 'magnifying glass' icon to selct a zoom area.</li>\n",
    "</ul>\n",
    "\n",
    "</div></div>\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px; border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\"> \n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Replace the code: <code>XScale = cb.utils.scale(Xlog, method='auto')</code> with: <code>XScale = cb.utils.scale(Xlog, method='pareto')</code> This will change the type of X column scaling.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">In the PCA function call <code>cb.plot.pca</code> replace the code: <code>pcy=2</code> with: <code>pcy=3</code> to change the plot from (PC1 vs. PC2) to (PC1 vs. PC3)</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Replace the code: <code>group_label=dataTable['SampleType']</code> with: <code>group_label=dataTable['Class']</code>. The PCA scores plot will now be grouped by the data in  column <code>Class</code> of the <code>dataTable</code>.</li>\n",
    "</ul>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,255); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"40\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">There are four type of scaling supported by the function <code>cimvb.utils.scale</code>: <code>'auto'</code>, <code>'range'</code>, <code>'pareto'</code>, <code>'vast'</code>, and <code>'level'</code>. In the context of metabolomics these are comprehensively reviewed by <a href=\"https://dx.doi.org/10.1186%2F1471-2164-7-142\">van den Berg <strong>et al</strong> 2006</a>.</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and scale the metabolite data from the dataTable \n",
    "\n",
    "peaklist = peakTableClean['Name']                   # Set peaklist to the metabolite names in the peakTableClean\n",
    "X = dataTable[peaklist].values                      # Extract X matrix from dataTable using peaklist\n",
    "Xlog = np.log10(X)                                  # Log scale (base-10)\n",
    "Xscale = cb.utils.scale(Xlog, method='auto')        # methods include auto, range, pareto, vast, and level\n",
    "Xknn = cb.utils.knnimpute(Xscale, k=3)              # missing value imputation (knn - 3 nearest neighbors)\n",
    "\n",
    "print(\"Xknn: {} rows & {} columns\".format(*Xknn.shape))\n",
    "\n",
    "cb.plot.pca(Xknn,\n",
    "            pcx=1,                                                  # pc for x-axis\n",
    "            pcy=2,                                                  # pc for y-axis\n",
    "            group_label=dataTable['SampleType'])                    # labels for Hover in PCA loadings plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "<a id='5'></a>\n",
    "<h2 id=\"5univariatestatisticsforcomparisonofgastriccancergcvshealthycontrolshe\" style=\"text-align: justify\">5. Univariate Statistics for comparison of Gastric Cancer (<code>GC</code>) vs Healthy Controls (<code>HE</code>)</h2>\n",
    "\n",
    "<p style=\"text-align: justify\">The data set uploaded into <code>dataTable</code> describes the <sup>1</sup>H-NMR urine metabolite profiles of individuals classified into three distinct groups: <code>GC</code> (gastric cancer), <code>BN</code> (benign), and <code>HE</code> (healthy). For this workflow we are interested in comparing only the differences in profiles between individuals classified as <code>GC</code> or <code>HE</code>.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The helper function <code>cb.utils.univariate_2class()</code> will take as input a data table where the observations represent data from two groups, and a corresponding table of metabolite peak information, and produce as output summary statistics of univariate comparisons between the two groups. The output is returned as a <code>pandas</code> dataframe, describing output from statistical tests such as Student's <em>t</em>-test and Shapiro-Wilks, and summaries of data quality, like the number and percentage of missing values.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">First, we reduce the data in <code>dataTable</code> to only those observations for <code>GC</code> and <code>HE</code> samples, and we define the <code>GC</code> class to be a positive outcome, in the variable <code>pos_outcome</code>. Next, we pass the reduced dataset and the cleaned <code>peakTable</code> to <code>cb.utils.univariate_2class()</code>, and store the returned dataframe in a new variable called <code>statsTable</code>. This is then displayed as before for interactive inspection and interpretation.</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,210); padding:2px; border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/mouse.png\">\n",
    "<div style=\"padding-left:80px\">\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Scroll up/down using the scroll bars.</li>\n",
    "<li style=\"text-align: justify\">Click on the column header to sort by that column (sort alternates between ascending and decending order).</li>\n",
    "<li style=\"text-align: justify\">Click on the left side of a header column for futher options, e.g.:\n",
    "<ul>\n",
    "    <li> For column <b>TtestStat</b> click on <b>Data Bars</b>.</li>\n",
    "    <li> For column <b>ShapiroPvalue</b> click on <b>Format -> exponential 5</b> (coverts to scientific notation). </li>\n",
    "    </ul></li>\n",
    "</div></div>\n",
    "\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px; border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">For data set <strong><em>GastricCancer_NMR.xlsx</em></strong> replace the code: <code>dataTable[(dataTable.Class == \"GC\") | (dataTable.Class == \"HE\")]</code> with: <br> <code>dataTable[(dataTable.Class == \"BN\") | (dataTable.Class == \"HE\")]</code> and replace <code>pos_outcome = \"GC\"</code> with: <code>pos_outcome = \"BN\"</code>. This will allow you to perform a 2-class statistical comparison between the patients with benign tumors and healthy controls.<br></li>\n",
    "\n",
    "<li style=\"text-align: justify\"><strong>OR</strong> for data set <strong><em>MTBLS290db.xlsx</em></strong> replace the code: <code>dataTable[(dataTable.Class == \"GC\") | (dataTable.Class == \"HE\")]</code>  with: <code>dataTable[(dataTable.Class == \"Patient\") | (dataTable.Class == \"Control\")]</code> and replace <code>pos_outcome = \"GC\"</code> with: <code>pos_outcome = \"Patient\"</code>. You will now perform a 2-class statistical comparison between the unhealthy patients and healthy controls.<br></li>\n",
    "\n",
    "<li style=\"text-align: justify\">In the statistical function call <code>cb.utils.univariate_2class</code> replace the code: <code>parametric=True</code> with: <code>parametric=False</code> to change the statistical test to a non-parametric Wilcoxon rank-sum test.</li>\n",
    "</ul>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,255); padding:2px;  border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"60\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\"><b>Note: Changing the outcome comparison will significantly affect the output of subsequent code cells.</b><br> So be sure to click on <mark><kbd>Cell</kbd></mark><font color='black'>→</font><mark><kbd>Run All Below</kbd></mark> then scroll down the notebook to see how changing this setting has changed all the cell outputs.</li>\n",
    "</ul>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select subset of Data for statistical comparison\n",
    "dataTable2 = dataTable[(dataTable.Class == \"GC\") | (dataTable.Class == \"HE\")]  # Reduce data table only to GC and HE class members\n",
    "pos_outcome = \"GC\" \n",
    "\n",
    "# Calculate basic statistics and create a statistics table.\n",
    "statsTable = cb.utils.univariate_2class(dataTable2,\n",
    "                                        peakTableClean,\n",
    "                                        group='Class',                # Column used to determine the groups\n",
    "                                        posclass=pos_outcome,         # Value of posclass in the group column\n",
    "                                        parametric=True)              # Set parametric = True or False\n",
    "\n",
    "# View and check StatsTable\n",
    "display(statsTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px;  border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"50\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\">\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Replace the filename <code>\"stats.xlsx\"</code> to <code>\"my_stats.xlsx\"</code><br></li>\n",
    "<li style=\"text-align: justify\">AND/OR replace <code>sheet_name='StatsTable'</code> with <code>sheet_name='myStatsTable'</code><br></li>\n",
    "</ul>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save StatsTable to Excel\n",
    "statsTable.to_excel(\"stats.xlsx\", sheet_name='StatsTable', index=False)\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "<p><a id='6'></a></p>\n",
    "    \n",
    "<h2 id=\"6machinelearning\">6. Machine Learning</h2>\n",
    "\n",
    "<p style=\"text-align: justify\">The remainder of this tutorial will describe the use of a 2-class <a href=\"https://en.wikipedia.org/wiki/Partial_least_squares_regression\">Partial Least Squares</a>-<a href=\"https://doi.org/10.1002/cem.713\">Discriminant Analysis</a> (PLS-DA) model to identify metabolites which, when combined in a <a href=\"https://en.wikipedia.org/wiki/Linear_equation\">linear equation</a>, are able to classify unknown samples as either <code>GC</code> or <code>HE</code> with a measurable degree of certainty.</p>\n",
    "\n",
    "\n",
    "<h3 id=\"61splittingdataintotrainingandtestsets\" style=\"text-align: justify\">6.1 Splitting data into Training and Test sets.</h3>\n",
    "<p style=\"text-align: justify\">\n",
    "Multivariate predictive models are prone to <a href=\"https://en.wikipedia.org/wiki/Overfitting\">overfitting</a>. In order to provide some level of independent evaluation it is common practice to split the source data set into two parts: <strong>training set</strong> and <strong>test set</strong>. The model is then optimised using the training data and independently evaluated using the test data. The true effectiveness of a model can only be assessed using the test data (<a href=\"https://link.springer.com/article/10.1007/s11306-007-0099-6\">Westerhuis <em>et al.</em> 2008</a>, <a href=\"https://doi.org/10.1007/s11306-012-0482-9\">Xia <em>et al.</em> 2012</a>). It is vitally important that both the training and test data are equally representative of the the sample population (in our example the urine metabotype of <em>Gastric Cancer</em> and the urine metabotype of <em>Healthy Control</em>). It is typical to split the data using a ratio of 2:1 (&#x2154; training, &#x2153; test) using <a href=\"https://en.wikipedia.org/wiki/Stratified_sampling\">stratified random selection</a>. If the purpose of model-building is exploratory, or sample numbers are small, this step is often ignored; however, care must be taken in interpreting a model that has not been tested on a dataset that is independent of the data it was trained on.\n",
    "</p>  \n",
    "\n",
    "<p style=\"text-align: justify\">\n",
    "We use the <code>dataTable2</code> dataframe created above, which contains a subset of the complete data suitable for a 2-class comparision (<code>GC</code> vs <code>HE</code>). Our goal is to split this dataframe into a <em>training</em> subset (<code>dataTrain</code>) which will be used to train our model, and a <em>test</em> set (<code>dataTest</code>), which will be used to evaluate the trained model. We will split the data such that number of <em>test</em> set samples is 25% of the the total. To do this, we will use the <a href=\"https://scikit-learn.org/stable/\"><code>scikit-learn</code> module</a>'s <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\"><code>train_test_split()</code> function</a>.\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify\">\n",
    "First, we need to ensure that the sample split - though random - is <em>stratified</em> so that the class membership is <em>balanced</em> to the same proportions in both the test and training sets. In order to do this, we need to supply a binary vector indicating stratification group membership.\n",
    "</p>\n",
    "\n",
    "<p style=\"text-align: justify\">\n",
    "The <code>train_test_split()</code> function expects a <em>binary</em> (<code>1</code>/<code>0</code>) list of <em>positive</em>/<em>negative</em> <strong>outcome</strong> indicators, not the <code>GC</code>/<code>HE</code> classes that we have. We convert the class information for each sample in <code>dataTable2</code> into <code>Y</code>, a list of <code>1</code>/<code>0</code> values, in the code cell below.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px; border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">If you have changed the comparsion groups in the default data to benign tumors (BN) vs. healthy controls (HE) then replace the code: <code>outcome == 'GC'</code> with: <code>outcome == 'BN'</code>.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">For data set <strong><em>MTBLS290db.xlsx</em></strong> replace the code: <code>outcome == 'GC'</code> with: <code>outcome == 'Patient'</code>.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Replace the code: <code>train_test_split(DataTable2, Y, test_size=0.25, stratify=Y)</code> with: <code>train_test_split(DataTable2, Y, test_size=0.1, stratify=Y)</code>. This will decrease the number of samples in the test set. How does this affect the results?</li>\n",
    "</ul>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,255); padding:2px;  border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\"><b>Note: If you change any of the code in the following Machine Learning sections you will change the performance of all the subsequent code cells.</b><br> So be sure to click on <mark><kbd>Cell</kbd></mark><font color='black'>→</font><mark><kbd>Run All Below</kbd></mark> then scroll down the notebook to see how changing this setting has changed all the cell outputs.</li>\n",
    "</ul>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Binary Y vector for stratifiying the samples\n",
    "outcomes = dataTable2['Class']                                  # Column that corresponds to Y class (should be 2 groups)\n",
    "Y = [1 if outcome == 'GC' else 0 for outcome in outcomes]       # Change Y into binary (GC = 1, HE = 0)  \n",
    "Y = np.array(Y)                                                 # convert boolean list into to a numpy array\n",
    "\n",
    "# Split DataTable2 and Y into train and test (with stratification)\n",
    "dataTrain, dataTest, Ytrain, Ytest = train_test_split(dataTable2, Y, test_size=0.25, stratify=Y, random_state=10)\n",
    "\n",
    "print(\"DataTrain = {} samples with {} postive cases.\".format(len(Ytrain),sum(Ytrain)))\n",
    "print(\"DataTest = {} samples with {} postive cases.\".format(len(Ytest),sum(Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "  \n",
    "<h3 id=\"62determineoptimalnumberofcomponentsforplsdamodel\" style=\"text-align: justify\">6.2. Determine optimal number of components for PLS-DA model</h3>\n",
    "<p style=\"text-align: justify\">The most common method to determine the optimal PLS-DA model configuration without overfitting is to use <a href=\"https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html\">k-fold cross-validation</a>. For PLS-DA, this will be a linear search of models having <i>$1$ to $N$</i> latent variables (components).\n",
    "    \n",
    "First, each PLS-DA configuration is trained using all the available data (<code>XTknn</code> and <code>Ytrain</code>). The generalised predictive ability of that model is then  evaluated using the same data - typically by calculating the <a href=\"https://en.wikipedia.org/wiki/Coefficient_of_determination\">coefficient of determination</a> $R^2$. This will generate $N$ evaluation scores ($R^2_1,R^2_2 ... R^2_N$).\n",
    "\n",
    "The training data is then split into <i>k</i> equally sized subsets (folds). For each of the PLS-DA configurations, $k$ models are built, such that each model is trained using $k-1$ <i>folds</i> and the remaining 1-fold is applied to the model and model predictions are recorded. The modeling process is implemented such than that after $k$ models each fold will have been *'held-out'* only once.\n",
    "\n",
    "The generalised predictive ability of the model is then evaluated by comparing the *'held-out'* model predictions to the expected classification (cross-validated coefficient of determination - $Q^2$). This will generate $N$ <i>cross-validated</i> evaluation scores scores ($Q^2_1,Q^2_2 ... Q^2_N$). If the values for $R^2$ and $Q^2$ are plotted against model complexity (number of latent variables), typically the value of $Q^2$ will be seen to rise and then fall. The point at which the $Q^2$ value begins to diverge from the $R^2$ value is considered the point at which the optimal number of components has been met without overfitting.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">In this section, we will perform 5-fold cross-validation using the training set we created above (<code>dataTrain</code>) to determine the optimal number of components to use in our PLS-DA model. First, we extract and scale the training data in <code>dataTrain</code> the same way as we did for PCA quality assessment in section 4 (log-transformation, scaling, and k-nearest-neighbour imputation of missing values).</p>\n",
    "\n",
    "<p style=\"text-align: justify\">First, in the cell below we extract and scale the training data in <code>dataTrain</code> the same way as we did for PCA quality assessment in section 4 (log-transformation, scaling, and k-nearest-neighbour imputation of missing values)..<br></p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px;  border: 20px solid rgb(255, 250, 250);  padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\"> \n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Replace the code: <code>cb.utils.scale(XTlog, method='auto')</code> with: <code>cb.utils.scale(XTlog, method='pareto')</code> This will change the type of X column scaling.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Replace the code: <code>cb.utils.scale(XTlog, method='auto')</code> with: <code>cb.utils.scale(XT, method='auto')</code> This change will ignore the  log transformed data (<code>XTlog</code>), and scale the raw <code>XT</code> data instead (thus missing out the log tranformation step of the data preprocessing).</li>\n",
    "</ul>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and scale the metabolite data from the dataTable\n",
    "peaklist = peakTableClean['Name']                           # Set peaklist to the metabolite names in the peakTableClean\n",
    "XT = dataTrain[peaklist]                                    # Extract X matrix from DataTrain using peaklist\n",
    "XTlog = np.log(XT)                                          # Log scale (base-10)\n",
    "XTscale = cb.utils.scale(XTlog, method='auto')              # methods include auto, pareto, vast, and level\n",
    "XTknn = cb.utils.knnimpute(XTscale, k=3)                    # missing value imputation (knn - 3 nearest neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<p style=\"text-align: justify\">Now we use the <code>cb.cross_val.kfold()</code> helper function to carry out 5-fold cross-validation of a set of PLS-DA models configured with different numbers of latent variables (1 to 6). This helper function is generally applicable, and the values being passed here are:</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\"><code>model</code>: the Python class describing the statistical model to train and validate. Here, this is <code>cb.model.PLS_SIMPLS</code>, a PLS model using the SIMPLS algorithm.</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><code>X</code>: the training data set (<code>XTknn</code>)</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><code>Y</code>: the known outcomes corresponding to the dataset in <code>X</code> (<code>Ytrain</code>)</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><code>param_dict</code>: a dictionary describing key:value pairs where the key is a parameter that is passed to the model, and the value is a collection of individual values to be passed to that parameter.</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><code>folds</code>: the number of folds in the cross-validation</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><code>bootnum</code>: the number of bootstrap samples used in computing confidence intervals</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">The <code>cb.cross_val.kfold()</code> function returns an object that we store in the <code>cv</code> variable. To actually run the cross-validation, we call the <code>cv.run()</code> method of this object. When the cell is run, a progress bar will appear:</p>\n",
    "\n",
    "<pre style=\"text-align: justify\"><code>Kfold: 100%|██████████| 100/100 [00:02&lt;00:00, 33.71it/s]\n",
    "</code></pre>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px;  border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250);  padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\"> \n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Replace the code: <code>param_dict={'n_components': [1,2,3,4,5,6]}</code> with: <code>param_dict={'n_components': [1,2,3,4,5,6,7,8,9,10]}</code>. This will increase the range of latent variables used to build PLS-DA models from a PLS-DA model with 1 latent variable to a PLS-DA model with 10 latent variables.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Replace the code: <code>folds=5</code> with: <code>folds=10</code>. This will change the number of folds in the k-fold cross validation.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Replace the code: <code>bootnum=100</code> with: <code>bootnum=500</code>. This will change the number of bootstrap samples used to calculate the 95% confidence interval for the $R^2$ and $Q^2$ curves. This will drastically slow down the code execution.</li>\n",
    "</ul>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(230,250,255); padding:2px; border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250);  padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/bulb.png\">\n",
    "<img align=\"right\" width=\"150\" src=\"images/R2Q2_ab.png\">\n",
    "<div style=\"padding-left:80px\">\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify; padding-right:200px\">For more information on the PLS SIMPLS algorithm refer to: De Jong, S., 1993. <a href= \"https://www.sciencedirect.com/science/article/abs/pii/016974399385002X\">SIMPLS: an alternative approach to partial least squares regression. Chemometrics and Intelligent Laboratory Systems, 18: 251–263</a></li>\n",
    "<li style=\"text-align: justify; padding-right:200px\">Although it is common practice to assume the optimal number of components for the PLS-DA model is chosen when $Q^2$  is at its apex (A), this is incorrect. Overtraining starts as soon as $Q^2$ significantly deviates from the $R^2$  trajectory. If the distance between $R^2$  and $Q^2$ gets large (>0.2 or the 95% CI stop overlapping) then one has to assume that the model is already overtrained. The point at which the $Q^2$ value begins to diverge from the $R^2$ value is considered point at which the optimal number of components has been met without overfitting (B). The $R^2$  vs. $(R^2 - Q^2$) plot is provided to aid decison making.</li>\n",
    "</ul>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,210); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"60\" src=\"images/mouse.png\">\n",
    "<div style=\"padding-left:80px\">\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Hover over the green data points in each of the plots to view the corresponding $R^2$  and $Q^2$ values.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Click on a point in one of the green plots. Notice that the two plots are linked.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Use the menu bar at the top right of the figure to save, scroll and zoom.</li>\n",
    "</ul>\n",
    "</div></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalise cross_val kfold (stratified) \n",
    "cv = cb.cross_val.kfold(model=cb.model.PLS_SIMPLS,                   # model; we are using the PLS_SIMPLS model\n",
    "                        X=XTknn,                                 \n",
    "                        Y=Ytrain,                               \n",
    "                        param_dict={'n_components': [1,2,3,4,5,6]},  # The numbers of latent variables to search                \n",
    "                        folds=5,                                     # folds; for the number of splits (k-fold)\n",
    "                        bootnum=100)                                 # num bootstraps for the Confidence Intervals\n",
    "\n",
    "\n",
    "cv.run()  # run the cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<p style=\"text-align: justify\">The object stored in the <code>cv</code> variable also has a <code>.plot()</code> method, which renders two views of $R^2$ and $Q^2$ statistics: difference ($R^2 - Q^2$), and absolute values of both metrics against the number of components, to aid in selecting the optimal number of components.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The point at which the $Q^2$ value begins to diverge from the $R^2$ value is considered to be the point at which the optimal number of components has been met without overfitting. In this case, the plots clearly indicate that the optimal number of latent variables in our model is two.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.plot() # plot cross validation statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "<h3 id=\"63trainandevaluateplsdamodel\" style=\"text-align: justify\">6.3 Train and evaluate PLS-DA model</h3>\n",
    "\n",
    "<p style=\"text-align: justify\">Now we have determined that the optimal number of components for this example data set is 2, we create a PLS-DA model with 2 latent variables, and evaluate its predictive ability. The <a href=\"https://doi.org/10.1016/0169-7439(93)85002-X\">implementation of PLS</a> we use is the <code>PLS_SIMPLS</code> class from the CIMCB helper module. We first create a PLS model object with two components, in the variable <code>modelPLS</code>:</p>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px; border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\"> \n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Replace the code: <code>n_components=2</code> with: <code>n_components=3</code>. This will increase the number of latent variables used in the PLS-DA model. Notice how this changes the apparent predictive ability of the model.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Replace the code: <code>cutoffscore=0.5</code> with: <code>cutoffscore=0.4</code> This will change the decision boundary for the classifier and alter the resulting perfomance statistics.</li>\n",
    "</ul>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,210); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"40\" src=\"images/mouse.png\">\n",
    "<div style=\"padding-left:80px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Hover over the green data points in each of the plots to view extra information.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">Use the menu bar at the right of the figures to save, scroll and zoom.<br></li>\n",
    "</ul>\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLS = cb.model.PLS_SIMPLS(n_components=2)  # Initalise the model with n_components = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<p style=\"text-align: justify\">Next we fit the model on the <code>XTknn</code> training dataset, with the values in <code>Ytrain</code> as the known response variables. We do this by calling the model's <code>.train()</code> method, with the predictor and response variables.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">This returns a list of values that are the <em>predicted</em> response variables, after model fitting.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = modelPLS.train(XTknn, Ytrain)  # Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<p style=\"text-align: justify\">Finally, we call the trained model's <code>.evaluate()</code> method, passing a <em>classification cutoff score</em> from which a standard set of model evaluations will be calculated from the model predictions (<a href=\"https://en.wikipedia.org/wiki/Coefficient_of_determination\">$R^2$</a>, <a href=\"https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test\">Mann-Whitney p-value</a>, <a href=\"https://doi.org/10.1007/s11306-012-0482-9\">Area under ROC curve</a>, <a href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision\">Accuracy, Precision</a>, <a href=\"https://en.wikipedia.org/wiki/Sensitivity_and_specificity\">Sensitivity, Specificity</a>). The model perfomance is also visualised using the following plots:</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">a <a href=\"https://www.data-to-viz.com/graph/violin.html\">violin plot</a> showing the distributions of negative and positive responses as violin plots and box-whisker plots, with an overlay of the predicted cutoff score that discriminates between classes (dashed line).</li>\n",
    "\n",
    "<li style=\"text-align: justify\">a <a href=\"https://books.google.com.au/books?id=7WBMrZ9umRYC\">probability density function</a> plot for each response type, with overlaid predicted cutoff score (dashed line)</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><a href=\"https://doi.org/10.1007/s11306-012-0482-9\">ROC curve</a> for the classifier, with 95% confidence interval (lighter shaded area), and the performance indicated with 95% CI.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">From these plots and the table we find that the trained classifier performs acceptably well.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLS.evaluate(cutoffscore=0.5)  # Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">  \n",
    "<h4 style=\"text-align: justify\"> Perform a permutation test for the PLS-DA model </h4>\n",
    "\n",
    "<p style=\"text-align: justify\">The reliability of our trained model can be assessed using a <a href=\"https://en.wikipedia.org/wiki/Resampling_(statistics)\"><em>permutation test</em></a>. In this test, the original data is randomised (<em>permuted</em> or 'shuffled') so that the predictor variables and response variables are mixed, and a new model is then trained and tested on the shuffled data. This is repeated many times so that the behaviour of models constructed from \"random\" data can be fairly assessed.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We can be confident that our model is being trained on relevant and meaningful features of the original dataset if the $R^2$ and $Q^2$ values generated from these models (with randomised data) are much lower than those found for our model trained on the original data.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The PLS model we are using from the CIMCB module has a <code>.permutation_test()</code> method that can perform this analysis for us. It returns a pair of graphs that can be used to interpret model performance.</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">$R^2$ and $Q^2$ against \"correlation of permuted data against original data\"</li>\n",
    "\n",
    "<li style=\"text-align: justify\">probability density functions for $R^2$ and $Q^2$, with the $R^2$ and $Q^2$ values found for the model trained on original data presented as ball-and-stick.</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">We see that the models trained on randomised/shuffled data have much lower $R^2$ and $Q^2$ values than the models trained on the original data, so we can be confident that the model represents meaningful features in the original dataset.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLS.permutation_test(nperm=100)  #nperm denotes to the number of permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.4'></a>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "<h3 id=\"64plotlatentvariableprojectionsforplsdamodel\" style=\"text-align: justify\">6.4. Plot latent variable projections for PLS-DA model</h3>\n",
    "\n",
    "<p style=\"text-align: justify\">The PLS model also provides a <code>.plot_projections()</code> method, so we can visually inspect characteristics of the fitted latent variables. This returns a grid of plots:</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">The diagonal shows probability density functions of each latent variable (LV) for each response class. The first latent variable (LV1) is at the top left of the plot.</li>\n",
    "\n",
    "<li style=\"text-align: justify\">The upper triangle shows ROC curves for each optimal discriminating pairwise combination of LVx and LVy scores</li>\n",
    "\n",
    "<li style=\"text-align: justify\">The lower triangle shows scatterplots of the scores for LVy against LVx, with a solid line indicating the direction of maximum discrimination</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">Where only one latent variable is fitted, a similar plot is produced to that with the <code>.evaluate()</code> method, with the addition of a scatterplot of latent variable scores)</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,255); padding:2px;  border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">These plots are useful to visualise to what degree each model component (latent variable) contribute to the model's discriminative ability. In the Gastric cancer example each individual component does not perform well in isolation. It is only when combined that a good prdicitve ability is revealed. In the bottom left figure the prjection scores plot includes a solid diagonal line describing the direction of prediction and a dashed line describing the orthogonal variance. In the method <a href=\"https://doi.org/10.1002%2Fcem.695\">orthogonal partial least squares</a> (O-PLS) this rotation is performed automatically to aid interpretation. However, these changes <a href=\"http://dx.doi.org/10.1016/j.trac.2009.08.006\">only improve the interpretability, not the predictivity, of the PLS models</a> (see <a href=\"https://fiehnlab.ucdavis.edu/staff/kind/statistics/concepts/opls-plsda\">Fiehnlab</a> for further discussion)\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPLS.plot_projections(label=\n",
    "                          dataTrain[['Idx','SampleID']], size=12) # size changes circle size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.5'></a>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "<h3 id=\"65plotfeatureimportancecoefficientplotandvipforplsdamodel\" style=\"text-align: justify\">6.5. Plot feature importance (Coefficient plot and VIP) for PLS-DA model</h3>\n",
    "\n",
    "<p style=\"text-align: justify\">Now that we have built a model and established that it represents meaningful features of the dataset, we determine the importance of specific peaks to the model's discriminatory power.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">To do this, in the cell below we use the PLS model's <code>plot_featureimportance()</code> method to render scatterplots of the <a href=\"https://doi.org/10.6084/m9.figshare.5696494.v3\">PLS regression <em>coefficient</em> values</a> for each metabolite, and <a href=\"https://books.google.com.au/books?id=58qLBQAAQBAJ\"><em>Variable Importance in Projection</em></a> (VIP) plots. The coefficient values provide information about the contribution of the peak to either a negative or positive classification for the sample, and peaks with VIP greater than unity (1) are considered to be \"important\" in the model.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We could generate these plots for the model as it was trained, but we would prefer to have an estimate of the robustness of these values, so we generate <a href=\"https://cds.cern.ch/record/526679/files/0412042312_TOC.pdf\">bootstrapped confidence intervals</a> with the model's <code>.calc_bootci()</code> method. Any metabolite coefficient with a confidence interval crossing the zero line is considered non-significant, and thus not \"important\" to the model.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">The <code>.plot_featureimportance()</code> method renders the two scatterplots, and also returns a new dataframe reporting these values, and their confidence intervals, which we capture in the variable <code>peakSheet</code>. </p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(230,250,255); padding:2px; border-top: 20px solid rgb(255, 250, 250); border-left: 20px solid rgb(255, 250, 250); border-right: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"80\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px\">\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">In statistics, the bootstrap procedure involves choosing random samples with replacement from a data set and calculating some statistic on those samples. The range of sample estimates you obtain enables you to establish the uncertainty of the quantity you are estimating. Sampling with replacement means that each observation in a sample is selected (and recorded) at random from the original dataset and then replaced, so it is possilbe for an observation can be selected multiple times. If the orginal data set contains N observations then each bootstrap sample contains N randomly selected observations. It has been shown that approximately 2/3 of the orginal data are include in each bootstrap sample (with 1/3 of the original data being included twice). Here we use bootstrap resampling to calculate confidence intervals for the coefficients in the PLS-DA model using the <a href=\"https://doi.org/10.1002/9780470057339.vab028\">'bootstrapping of observations'</a> method.\n",
    "</ul>\n",
    "</div></div>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"60\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\"> </p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Replace the code: <code>type='bca'</code> with either <code>type='perc'</code> or <code>type='bc'</code> to change from <a href=\"https://doi.org/10.2307%2F2289144\">Bias corrected and accelerated percentile method</a> to either <a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.473.2742&amp;rep=rep1&amp;type=pdf\"><em>Bias corrected percentile method</em> or <em>percentile method</em></a></li>\n",
    "\n",
    "<li style=\"text-align: justify\">Replace the code: <code>sort=False</code> with: <code>sort=True</code>. This will sort the metabolites in decending order of importance.</li>\n",
    "</ul>\n",
    "\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the bootstrapped confidence intervals \n",
    "modelPLS.calc_bootci(type='bca', bootnum=200)                # decrease bootnum if it this takes too long on your machine\n",
    "\n",
    "# Plot the feature importance plots, and return a new Peaksheet \n",
    "peakSheet = modelPLS.plot_featureimportance(peakTableClean,\n",
    "                                            peaklist,\n",
    "                                            ylabel='Label',  # change ylabel to 'Name' \n",
    "                                            sort=False)      # change sort to False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "<h3 id=\"66testmodelwithnewdatausingtestsetfromsection61\" style=\"text-align: justify\">6.6. Test model with new data (using test set from section 6.1)</h3>\n",
    "\n",
    "<p style=\"text-align: justify\">So far, we have trained and tested our PLS classifier on a single training dataset. This risks <em>overfitting</em> as we could be optimising the performance of the model on this dataset such that it cannot <em>generalise</em>, in the sense that it may not perform as well on a dataset that it has not already seen.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">To see if the model can <em>generalise</em>, we must test our trained model using a new dataset that it has not already encountered. In section 6.1 we divided our original complete dataset into four components: <code>datatrain</code>, <code>Ytrain</code>, <code>dataTest</code> and <code>Ytest</code>. Our trained model has not seen the <code>dataTest</code> and <code>Ytest</code> values that we have <em>held out</em>, so these can be used to evaluate model preformance on new data.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">We begin by transforming and scaling this <em>holdout</em> dataset in the same way as we did for the training data. To do this, we first find the mean and variance of our transformed training data set <code>XTlog</code> with the <code>cb.utils.scale()</code> function, so that we can use these values to scale the <em>holdout</em> data.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,255); padding:2px;  border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"60\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Note: It is important that the test data is tranformed and scaled using the same parameters as the training data. If the training data is log transformed then the test data must also be log transformed, otherwise the test predictions will be inappropriate, and likely highly imprecise. Equally the scaling must be performed using the scaling factors derived from the training data (e.g. mean-centred to the traning data mean, and normalised to the training data standard deviation.</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mu and sigma from the training dataset to use for the Xtest scaling\n",
    "mu, sigma  = cb.utils.scale(XTlog, return_mu_sigma=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "<p style=\"text-align: justify\">Next, we extract the peak data for our holdout <code>dataTest</code> set, and put this in the variable <code>XV</code>. As before, we take the log transform (<code>XVlog</code>), scale the data in the same way as the training data (<code>XVscale</code>; note that we specify <code>mu</code> and <code>sigma</code> as calculated above), and impute missing values to give the final <em>holdout</em> test set <code>XVknn</code>.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull of Xtest from DataTest using peaklist ('Name' column in PeakTable)\n",
    "peaklist = peakTableClean.Name \n",
    "XV = dataTest[peaklist].values\n",
    "\n",
    "# Log transform, unit-scale and knn-impute missing values for Xtest\n",
    "XVlog = np.log(XV)\n",
    "XVscale  = cb.utils.scale(XVlog, method='auto', mu=mu, sigma=sigma) \n",
    "XVknn = cb.utils.knnimpute(XVscale, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<p style=\"text-align: justify\">Now we predict a new set of response variables from <code>XVknn</code> as input, using our trained model and its <code>.test()</code> method, and then evaluate the performance of model prediction against the known values in <code>Ytest</code> using the <code>.evaluate()</code> method (as in section 6.3).</p>\n",
    "\n",
    "<p style=\"text-align: justify\">Three plots are generated, showing comparisons of the performance of the model on training and holdout test datasets.</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">a violin plot showing the distribution of known positive and negative in both training and test sets, and the class cut-off (dotted line)</li>\n",
    "\n",
    "<li style=\"text-align: justify\">probability density functions for positive and negative classes in the training and test sets (the training set datapoints are rendered as more opaque than the test set data in this figure)</li>\n",
    "\n",
    "<li style=\"text-align: justify\">ROC curves of model performance on training and test sets</li>\n",
    "</ul>\n",
    "\n",
    "<p style=\"text-align: justify\">A table of performance metrics for both datasets is shown below the figures.</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(210,250,255); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"40\" src=\"images/bulb.png\">\n",
    "<div style=\"padding-left:80px; text-align: justify\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Note: Although the calulcated bootstrap confidence intervals for prediciton will give an estimate of uncertainty of prediction the only way to definitively evaluate any model is with an independent test set, as shown in this plot.  </li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate Ypredicted score using modelPLS.test\n",
    "YVpred = modelPLS.test(XVknn)\n",
    "\n",
    "# Evaluate Ypred against Ytest\n",
    "evals = [Ytest, YVpred]    # alternative formats: (Ytest, Ypred) or np.array([Ytest, Ypred])\n",
    "#modelPLS.evaluate(evals, specificity=0.9)\n",
    "modelPLS.evaluate(evals, cutoffscore=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6.7'></a>\n",
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px;  padding-left: 1em; padding-right: 1em;\">\n",
    "    \n",
    "<h3 id=\"67exportresultstoexcel\" style=\"text-align: justify\">6.7. Export results to Excel</h3>\n",
    "\n",
    "<p style=\"text-align: justify\">Finally, we will save our results in a persistent Excel spreadsheet.</p>\n",
    "\n",
    "<p style=\"text-align: justify\">Unlike section 5, we want to save two sheets in a single Excel workbook called <code>modelPLS.xlsx</code>. We want to save one sheet showing the holdout test data (with results from <code>YVpred</code>), and a separate sheet showing the peaks with their residual coefficients and VIP scores. </p>\n",
    "\n",
    "<p style=\"text-align: justify\">Firstly, we generate a dataframe containing the test dataset and the model's predictions. This will have columns for</p>\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\"><code>idx</code>: sample index</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><code>SampleID</code>: sample ID</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><code>class</code>: sample class (<code>GC</code> or <code>HE</code>)</li>\n",
    "\n",
    "<li style=\"text-align: justify\"><code>YPred</code>: predicted response variable from the trained model</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgb(255,210,210); padding:2px; border: 20px solid rgb(255, 250, 250); padding-right: 1em;\">\n",
    "<img align=\"left\" width=\"50\" src=\"images/cog2.png\">\n",
    "<div style=\"padding-left:80px\">\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li style=\"text-align: justify\">Replace the filename <code>\"modelPLS.xlsx\"</code> to <code>\"myModelPLS.xlsx\"</code><br></li>\n",
    "\n",
    "<li style=\"text-align: justify\">AND/OR change <code>sheet_name='Datasheet'</code> / <code>sheet_name='PeakSheet'</code> as appropriate<br></li>\n",
    "</ul>\n",
    "</div></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataSheet as 'Idx', 'SampleID', and 'Class' from DataTest\n",
    "dataSheet = dataTest[[\"Idx\", \"SampleID\", \"Class\"]].copy() \n",
    "\n",
    "# Add 'Ypred' to Datasheet\n",
    "dataSheet['Ypred'] = YVpred \n",
    "\n",
    "display(dataSheet) # View and check the dataTable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<p style=\"text-align: justify\">In section 5 we saved a single dataframe to an Excel workbook, as a single worksheet. Here, we want to save two worksheets. This means we can't use the <code>.to_excel()</code> method of a dataframe directly to write twice to the same file. Instead, we must create a <code>pd.ExcelWriter</code> object, and add each dataframe in turn to this object. When we are finished adding datframes, we can use the object's <code>.save()</code> method to write the Excel workbook with several worksheets (one per dataframe) to a single file.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty excel workbook\n",
    "writer = pd.ExcelWriter(\"modelPLS.xlsx\")     # provide the filename for the Excel file\n",
    "\n",
    "# Add each dataframe to the workbook in turn, as a separate worksheet\n",
    "dataSheet.to_excel(writer, sheet_name='Datasheet', index=False)\n",
    "peakSheet.to_excel(writer, sheet_name='Peaksheet', index=False)\n",
    "\n",
    "# Write the Excel workbook to disk\n",
    "writer.save()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<p>Well done! You have finished the LC-MS data analysis.</p>\n",
    "\n",
    "Now go back to **2. Load Data and Peak Sheet** to do the NMR data analysis\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:10px; padding-left: 1em; padding-right: 1em;\">\n",
    "\n",
    "<p>Congrats you have analysed a LC-MS and an NMR data set</p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "338px",
    "width": "315px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "184px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
